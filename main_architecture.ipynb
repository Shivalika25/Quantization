{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main-architecture.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxcR1ckcTTZL"
      },
      "source": [
        "\n",
        "# %tensorflow_version 1.x\n",
        "# import tensorflow as tf\n",
        "# from tensorflow import keras"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbupnJybyG5s",
        "outputId": "82cc9b18-de58-44ca-e048-0c9f858c2086",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "! pip uninstall -y tensorflow\n",
        "! pip install -q tf-nightly\n",
        "! pip install -q tensorflow-model-optimization\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.3.0:\n",
            "  Successfully uninstalled tensorflow-2.3.0\n",
            "\u001b[K     |████████████████████████████████| 394.8MB 42kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8MB 54.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3MB 48.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 471kB 61.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 14.5MB 250kB/s \n",
            "\u001b[K     |████████████████████████████████| 10.6MB 57.7MB/s \n",
            "\u001b[31mERROR: fancyimpute 0.4.3 requires tensorflow, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 174kB 4.4MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eoN1fKbvmN1"
      },
      "source": [
        "Reference Link :https://www.tensorflow.org/model_optimization/guide/quantization/training_comprehensive_guide.md\n",
        "\n",
        "Future Useful Links\n",
        "1. https://www.tensorflow.org/model_optimization/guide/quantization/training_comprehensive_guide.md\n",
        "2.https://colab.research.google.com/gist/ohtaman/c1cf119c463fd94b0da50feea320ba1e/edgetpu-with-keras.ipynb#scrollTo=jWp9_I06ZjDo\n",
        "2.https://paperswithcode.com/paper/quantization-and-training-of-neural-networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivM8OIYXfFG7",
        "outputId": "2806224c-6bf5-4b6d-84a8-9d61a7ead662",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# train_images=train_images.reshape(60000, 28, 28)\n",
        "# test_images=test_images.reshape(10000, 28, 28)\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 to 1.\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "# Batches of 64\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).batch(64)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(64)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTQ1eSrEmdVI"
      },
      "source": [
        "from tensorflow import Tensor\n",
        "def sgcn_block(x:Tensor,kernel_size: int):\n",
        "\n",
        "  x = keras.layers.DepthwiseConv2D(kernel_size=(1, 11),padding='same',depth_multiplier=1)(x)\n",
        "  x1 = keras.layers.Conv2D(190,(1,1))(x)\n",
        "  x1 = keras.layers.BatchNormalization(fused=False)(x1)\n",
        "  x1 = keras.layers.Activation('relu')(x1)\n",
        "  # x1 = keras.layers.ReLU()(x1)\n",
        "\n",
        "  x2 = keras.layers.Conv2D(190,(1,1))(x)\n",
        "  x2 = keras.layers.BatchNormalization(fused=False)(x2)\n",
        "  x2 = keras.layers.Activation('sigmoid')(x2)\n",
        "\n",
        "  out=keras.layers.Multiply()([x1,x2])\n",
        "  # quantize_annotate_layer(tf.keras.layers.Dense(20, input_shape=(20,)), ModifiedDenseQuantizeConfig()),\n",
        "  print(out.shape)\n",
        "  return out\n",
        "\n",
        "def create_sgcn():\n",
        "  inputs=keras.Input(shape=(28, 28,1))\n",
        "  num_filters=64 #how many?\n",
        "\n",
        "  # t=keras.layers.BatchNormalization(fused=False)(inputs)\n",
        "  t=tf.keras.layers.Conv2D(num_filters,5)(inputs)\n",
        "  t=tf.keras.layers.MaxPool2D((2,2))(t)\n",
        "  t=keras.layers.Activation('relu')(t)\n",
        "  t=tf.keras.layers.Conv2D(num_filters,5)(t)\n",
        "  t=tf.keras.layers.MaxPool2D((2,2))(t)\n",
        "  t=keras.layers.Activation('relu')(t)\n",
        "  print(\"shape***\",t.shape)\n",
        "  s=t.shape\n",
        "  t=keras.layers.Reshape(target_shape=(1,s[1]*s[2],s[3]))(t)\n",
        "  # t=keras.layers.Flatten()(t) #necessary? transpose or expand dim (2nd dimension is channel)\n",
        "  print(\"shape squeeze\",t.shape)\n",
        "  # input2=keras.Input(shape=(32,32))\n",
        "  # t=keras.layers.Reshape(target_shape=(32,32))(t)\n",
        "  # t=keras.layers.BatchNormalization(fused=False)(input2)\n",
        "  for i in range(1,13): #correct?\n",
        "    t=sgcn_block(t,5)\n",
        "    if i%2!=0:\n",
        "      print(i)\n",
        "      t1=t\n",
        "    if i%2 !=0 & i!=1:\n",
        "      print(\"i:\",i)\n",
        "      t=keras.layers.Add()([t1,t])\n",
        "  print(\"hi\",t.shape)\n",
        "  out=keras.layers.Flatten()(t)\n",
        "  out= keras.layers.Dense(10, activation=\"softmax\")(out)\n",
        "  print(out.shape)\n",
        "  model=keras.Model(inputs, out, name=\"SGCN\")\n",
        "  model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "  print(model.summary())\n",
        "  return model\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXHPUGjhT4CU",
        "outputId": "33e437b2-73c4-480a-e689-16292a25b356",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# model.compile(\n",
        "#     loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "#     optimizer=keras.optimizers.RMSprop(),\n",
        "#     metrics=[\"accuracy\"],\n",
        "# )\n",
        "model=create_sgcn()\n",
        "\n",
        "history = model.fit(train_images, train_labels, batch_size=64, epochs=2, validation_split=0.2)\n",
        "\n",
        "test_scores = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(\"Test loss:\", test_scores[0])\n",
        "print(\"Test accuracy:\", test_scores[1])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape*** (None, 4, 4, 64)\n",
            "shape squeeze (None, 1, 16, 64)\n",
            "(None, 1, 16, 190)\n",
            "1\n",
            "i: 1\n",
            "(None, 1, 16, 190)\n",
            "(None, 1, 16, 190)\n",
            "3\n",
            "i: 3\n",
            "(None, 1, 16, 190)\n",
            "(None, 1, 16, 190)\n",
            "5\n",
            "i: 5\n",
            "(None, 1, 16, 190)\n",
            "(None, 1, 16, 190)\n",
            "7\n",
            "i: 7\n",
            "(None, 1, 16, 190)\n",
            "(None, 1, 16, 190)\n",
            "9\n",
            "i: 9\n",
            "(None, 1, 16, 190)\n",
            "(None, 1, 16, 190)\n",
            "11\n",
            "i: 11\n",
            "(None, 1, 16, 190)\n",
            "hi (None, 1, 16, 190)\n",
            "(None, 10)\n",
            "Model: \"SGCN\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 24, 24, 64)   1664        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 12, 12, 64)   0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 12, 12, 64)   0           max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 8, 8, 64)     102464      activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 4, 4, 64)     0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 4, 4, 64)     0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 1, 16, 64)    0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d (DepthwiseConv (None, 1, 16, 64)    384         reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 1, 16, 190)   12350       depthwise_conv2d[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 1, 16, 190)   12350       depthwise_conv2d[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 1, 16, 190)   760         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 1, 16, 190)   760         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 1, 16, 190)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 1, 16, 190)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "multiply (Multiply)             (None, 1, 16, 190)   0           activation_2[0][0]               \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 1, 16, 190)   0           multiply[0][0]                   \n",
            "                                                                 multiply[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_1 (DepthwiseCo (None, 1, 16, 190)   1140        add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 1, 16, 190)   36290       depthwise_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 1, 16, 190)   36290       depthwise_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 1, 16, 190)   760         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 1, 16, 190)   760         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 1, 16, 190)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 1, 16, 190)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "multiply_1 (Multiply)           (None, 1, 16, 190)   0           activation_4[0][0]               \n",
            "                                                                 activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_2 (DepthwiseCo (None, 1, 16, 190)   1140        multiply_1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 1, 16, 190)   36290       depthwise_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 1, 16, 190)   36290       depthwise_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 1, 16, 190)   760         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 1, 16, 190)   760         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 1, 16, 190)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 1, 16, 190)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "multiply_2 (Multiply)           (None, 1, 16, 190)   0           activation_6[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 1, 16, 190)   0           multiply_2[0][0]                 \n",
            "                                                                 multiply_2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_3 (DepthwiseCo (None, 1, 16, 190)   1140        add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 1, 16, 190)   36290       depthwise_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 1, 16, 190)   36290       depthwise_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 1, 16, 190)   760         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 1, 16, 190)   760         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 1, 16, 190)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 1, 16, 190)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "multiply_3 (Multiply)           (None, 1, 16, 190)   0           activation_8[0][0]               \n",
            "                                                                 activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_4 (DepthwiseCo (None, 1, 16, 190)   1140        multiply_3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 1, 16, 190)   36290       depthwise_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 1, 16, 190)   36290       depthwise_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 1, 16, 190)   760         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 1, 16, 190)   760         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 1, 16, 190)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 1, 16, 190)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "multiply_4 (Multiply)           (None, 1, 16, 190)   0           activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 1, 16, 190)   0           multiply_4[0][0]                 \n",
            "                                                                 multiply_4[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_5 (DepthwiseCo (None, 1, 16, 190)   1140        add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 1, 16, 190)   36290       depthwise_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 1, 16, 190)   36290       depthwise_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 1, 16, 190)   760         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 1, 16, 190)   760         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 1, 16, 190)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 1, 16, 190)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "multiply_5 (Multiply)           (None, 1, 16, 190)   0           activation_12[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_6 (DepthwiseCo (None, 1, 16, 190)   1140        multiply_5[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 1, 16, 190)   36290       depthwise_conv2d_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 1, 16, 190)   36290       depthwise_conv2d_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 1, 16, 190)   760         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 1, 16, 190)   760         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 1, 16, 190)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 1, 16, 190)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "multiply_6 (Multiply)           (None, 1, 16, 190)   0           activation_14[0][0]              \n",
            "                                                                 activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 1, 16, 190)   0           multiply_6[0][0]                 \n",
            "                                                                 multiply_6[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_7 (DepthwiseCo (None, 1, 16, 190)   1140        add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 1, 16, 190)   36290       depthwise_conv2d_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 1, 16, 190)   36290       depthwise_conv2d_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 1, 16, 190)   760         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 1, 16, 190)   760         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 1, 16, 190)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 1, 16, 190)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "multiply_7 (Multiply)           (None, 1, 16, 190)   0           activation_16[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_8 (DepthwiseCo (None, 1, 16, 190)   1140        multiply_7[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 1, 16, 190)   36290       depthwise_conv2d_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 1, 16, 190)   36290       depthwise_conv2d_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 1, 16, 190)   760         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 1, 16, 190)   760         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 1, 16, 190)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 1, 16, 190)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "multiply_8 (Multiply)           (None, 1, 16, 190)   0           activation_18[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 1, 16, 190)   0           multiply_8[0][0]                 \n",
            "                                                                 multiply_8[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_9 (DepthwiseCo (None, 1, 16, 190)   1140        add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 1, 16, 190)   36290       depthwise_conv2d_9[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 1, 16, 190)   36290       depthwise_conv2d_9[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 1, 16, 190)   760         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 1, 16, 190)   760         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 1, 16, 190)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 1, 16, 190)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "multiply_9 (Multiply)           (None, 1, 16, 190)   0           activation_20[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_10 (DepthwiseC (None, 1, 16, 190)   1140        multiply_9[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 1, 16, 190)   36290       depthwise_conv2d_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 1, 16, 190)   36290       depthwise_conv2d_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 1, 16, 190)   760         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 1, 16, 190)   760         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 1, 16, 190)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 1, 16, 190)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "multiply_10 (Multiply)          (None, 1, 16, 190)   0           activation_22[0][0]              \n",
            "                                                                 activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 1, 16, 190)   0           multiply_10[0][0]                \n",
            "                                                                 multiply_10[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_11 (DepthwiseC (None, 1, 16, 190)   1140        add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 1, 16, 190)   36290       depthwise_conv2d_11[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 1, 16, 190)   36290       depthwise_conv2d_11[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 1, 16, 190)   760         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 1, 16, 190)   760         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 1, 16, 190)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 1, 16, 190)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "multiply_11 (Multiply)          (None, 1, 16, 190)   0           activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 3040)         0           multiply_11[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30410       flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 988,782\n",
            "Trainable params: 979,662\n",
            "Non-trainable params: 9,120\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/2\n",
            "750/750 [==============================] - 220s 288ms/step - loss: 0.4286 - accuracy: 0.8645 - val_loss: 0.1578 - val_accuracy: 0.9520\n",
            "Epoch 2/2\n",
            "750/750 [==============================] - 215s 287ms/step - loss: 0.0612 - accuracy: 0.9820 - val_loss: 0.1020 - val_accuracy: 0.9741\n",
            "313/313 - 11s - loss: 0.0900 - accuracy: 0.9786\n",
            "Test loss: 0.08995679020881653\n",
            "Test accuracy: 0.978600025177002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ry1zLFisU-Ir"
      },
      "source": [
        "**Quantized Aware Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaPXeA2aVals"
      },
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "def apply_quantization_to_layer(layer):\n",
        "  if isinstance(layer, tf.keras.layers.MaxPool2D):\n",
        "    return tfmot.quantization.keras.quantize_annotate_layer(layer)\n",
        "  if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "    return tfmot.quantization.keras.quantize_annotate_layer(layer)\n",
        "  if isinstance(layer, tf.keras.layers.Dense):\n",
        "    return tfmot.quantization.keras.quantize_annotate_layer(layer)\n",
        "  if isinstance(layer, tf.keras.layers.Dense):\n",
        "    return tfmot.quantization.keras.quantize_annotate_layer(layer)\n",
        "  if isinstance(layer, tf.keras.layers.SeparableConv1D):\n",
        "    return tfmot.quantization.keras.quantize_annotate_layer(layer)\n",
        "  if isinstance(layer, tf.keras.layers.Flatten):\n",
        "    return tfmot.quantization.keras.quantize_annotate_layer(layer)\n",
        "  if isinstance(layer, tf.keras.layers.Add):\n",
        "  #   return tfmot.quantization.keras.quantize_annotate_layer(layer)\n",
        "  # if isinstance(layer, tf.keras.layers.Multiply):\n",
        "    return tfmot.quantization.keras.quantize_annotate_layer(layer)\n",
        "  # if isinstance(layer, tf.keras.layers.Activation):\n",
        "  #   return tfmot.quantization.keras.quantize_annotate_layer(layer)\n",
        "  \n",
        "  return layer"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxbBe4pxpeHk"
      },
      "source": [
        "# quant_aware_model = tfmot.quantization.keras.quantize_model(model)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzVcck6LZxrr"
      },
      "source": [
        "#Use `tf.keras.models.clone_model` to apply #apply_quantization_to_layer` \n",
        "# to the layers of the model.\n",
        "\n",
        "annotated_model = tf.keras.models.clone_model(\n",
        "    model,\n",
        "    clone_function=apply_quantization_to_layer\n",
        "    \n",
        ")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8W19UREVHZV",
        "outputId": "91f6d8de-a7f1-4007-adc1-7d5fe43ea002",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# model = quantize_annotate_model(tf.keras.Sequential([\n",
        "#    quantize_annotate_layer(CustomLayer(20, input_shape=(20,)), DefaultDenseQuantizeConfig()),\n",
        "#    tf.keras.layers.Flatten()\n",
        "# ]))\n",
        "\n",
        "# Now that the layers are annotated,\n",
        "# `quantize_apply` actually makes the model quantization aware.\n",
        "quant_aware_model = tfmot.quantization.keras.quantize_apply(annotated_model)\n",
        "# with quantize_scope(\n",
        "#   {'DefaultQuantizeConfig': DefaultQuantizeConfig):\n",
        "#   # Use `quantize_apply` to actually make the model quantization aware.\n",
        "#   quant_aware_model = tfmot.quantization.keras.quantize_apply(annotated_model)\n",
        "quant_aware_model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"SGCN\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "quantize_layer (QuantizeLayer)  (None, 28, 28, 1)    3           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "quant_conv2d (QuantizeWrapper)  (None, 24, 24, 64)   1795        quantize_layer[1][0]             \n",
            "__________________________________________________________________________________________________\n",
            "quant_max_pooling2d (QuantizeWr (None, 12, 12, 64)   1           quant_conv2d[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 12, 12, 64)   0           quant_max_pooling2d[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "quant_conv2d_1 (QuantizeWrapper (None, 8, 8, 64)     102595      activation[1][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "quant_max_pooling2d_1 (Quantize (None, 4, 4, 64)     1           quant_conv2d_1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 4, 4, 64)     0           quant_max_pooling2d_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 1, 16, 64)    0           activation_1[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "quant_depthwise_conv2d (Quantiz (None, 1, 16, 64)    389         reshape[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "quant_conv2d_2 (QuantizeWrapper (None, 1, 16, 190)   12733       quant_depthwise_conv2d[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "quant_conv2d_3 (QuantizeWrapper (None, 1, 16, 190)   12733       quant_depthwise_conv2d[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 1, 16, 190)   760         quant_conv2d_2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 1, 16, 190)   760         quant_conv2d_3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 1, 16, 190)   0           batch_normalization[1][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 1, 16, 190)   0           batch_normalization_1[1][0]      \n",
            "__________________________________________________________________________________________________\n",
            "multiply (Multiply)             (None, 1, 16, 190)   0           activation_2[1][0]               \n",
            "                                                                 activation_3[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "quant_add (QuantizeWrapper)     (None, 1, 16, 190)   3           multiply[1][0]                   \n",
            "                                                                 multiply[1][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "quant_depthwise_conv2d_1 (Quant (None, 1, 16, 190)   1145        quant_add[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "quant_conv2d_4 (QuantizeWrapper (None, 1, 16, 190)   36673       quant_depthwise_conv2d_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "quant_conv2d_5 (QuantizeWrapper (None, 1, 16, 190)   36673       quant_depthwise_conv2d_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 1, 16, 190)   760         quant_conv2d_4[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 1, 16, 190)   760         quant_conv2d_5[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 1, 16, 190)   0           batch_normalization_2[1][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 1, 16, 190)   0           batch_normalization_3[1][0]      \n",
            "__________________________________________________________________________________________________\n",
            "multiply_1 (Multiply)           (None, 1, 16, 190)   0           activation_4[1][0]               \n",
            "                                                                 activation_5[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "quant_depthwise_conv2d_2 (Quant (None, 1, 16, 190)   1145        multiply_1[1][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "quant_conv2d_6 (QuantizeWrapper (None, 1, 16, 190)   36673       quant_depthwise_conv2d_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "quant_conv2d_7 (QuantizeWrapper (None, 1, 16, 190)   36673       quant_depthwise_conv2d_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 1, 16, 190)   760         quant_conv2d_6[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 1, 16, 190)   760         quant_conv2d_7[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 1, 16, 190)   0           batch_normalization_4[1][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 1, 16, 190)   0           batch_normalization_5[1][0]      \n",
            "__________________________________________________________________________________________________\n",
            "multiply_2 (Multiply)           (None, 1, 16, 190)   0           activation_6[1][0]               \n",
            "                                                                 activation_7[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "quant_add_1 (QuantizeWrapper)   (None, 1, 16, 190)   3           multiply_2[1][0]                 \n",
            "                                                                 multiply_2[1][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "quant_depthwise_conv2d_3 (Quant (None, 1, 16, 190)   1145        quant_add_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "quant_conv2d_8 (QuantizeWrapper (None, 1, 16, 190)   36673       quant_depthwise_conv2d_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "quant_conv2d_9 (QuantizeWrapper (None, 1, 16, 190)   36673       quant_depthwise_conv2d_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 1, 16, 190)   760         quant_conv2d_8[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 1, 16, 190)   760         quant_conv2d_9[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 1, 16, 190)   0           batch_normalization_6[1][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 1, 16, 190)   0           batch_normalization_7[1][0]      \n",
            "__________________________________________________________________________________________________\n",
            "multiply_3 (Multiply)           (None, 1, 16, 190)   0           activation_8[1][0]               \n",
            "                                                                 activation_9[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "quant_depthwise_conv2d_4 (Quant (None, 1, 16, 190)   1145        multiply_3[1][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "quant_conv2d_10 (QuantizeWrappe (None, 1, 16, 190)   36673       quant_depthwise_conv2d_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "quant_conv2d_11 (QuantizeWrappe (None, 1, 16, 190)   36673       quant_depthwise_conv2d_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 1, 16, 190)   760         quant_conv2d_10[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 1, 16, 190)   760         quant_conv2d_11[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 1, 16, 190)   0           batch_normalization_8[1][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 1, 16, 190)   0           batch_normalization_9[1][0]      \n",
            "__________________________________________________________________________________________________\n",
            "multiply_4 (Multiply)           (None, 1, 16, 190)   0           activation_10[1][0]              \n",
            "                                                                 activation_11[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "quant_add_2 (QuantizeWrapper)   (None, 1, 16, 190)   3           multiply_4[1][0]                 \n",
            "                                                                 multiply_4[1][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "quant_depthwise_conv2d_5 (Quant (None, 1, 16, 190)   1145        quant_add_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "quant_conv2d_12 (QuantizeWrappe (None, 1, 16, 190)   36673       quant_depthwise_conv2d_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "quant_conv2d_13 (QuantizeWrappe (None, 1, 16, 190)   36673       quant_depthwise_conv2d_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 1, 16, 190)   760         quant_conv2d_12[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 1, 16, 190)   760         quant_conv2d_13[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 1, 16, 190)   0           batch_normalization_10[1][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 1, 16, 190)   0           batch_normalization_11[1][0]     \n",
            "__________________________________________________________________________________________________\n",
            "multiply_5 (Multiply)           (None, 1, 16, 190)   0           activation_12[1][0]              \n",
            "                                                                 activation_13[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "quant_depthwise_conv2d_6 (Quant (None, 1, 16, 190)   1145        multiply_5[1][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "quant_conv2d_14 (QuantizeWrappe (None, 1, 16, 190)   36673       quant_depthwise_conv2d_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "quant_conv2d_15 (QuantizeWrappe (None, 1, 16, 190)   36673       quant_depthwise_conv2d_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 1, 16, 190)   760         quant_conv2d_14[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 1, 16, 190)   760         quant_conv2d_15[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 1, 16, 190)   0           batch_normalization_12[1][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 1, 16, 190)   0           batch_normalization_13[1][0]     \n",
            "__________________________________________________________________________________________________\n",
            "multiply_6 (Multiply)           (None, 1, 16, 190)   0           activation_14[1][0]              \n",
            "                                                                 activation_15[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "quant_add_3 (QuantizeWrapper)   (None, 1, 16, 190)   3           multiply_6[1][0]                 \n",
            "                                                                 multiply_6[1][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "quant_depthwise_conv2d_7 (Quant (None, 1, 16, 190)   1145        quant_add_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "quant_conv2d_16 (QuantizeWrappe (None, 1, 16, 190)   36673       quant_depthwise_conv2d_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "quant_conv2d_17 (QuantizeWrappe (None, 1, 16, 190)   36673       quant_depthwise_conv2d_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 1, 16, 190)   760         quant_conv2d_16[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 1, 16, 190)   760         quant_conv2d_17[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 1, 16, 190)   0           batch_normalization_14[1][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 1, 16, 190)   0           batch_normalization_15[1][0]     \n",
            "__________________________________________________________________________________________________\n",
            "multiply_7 (Multiply)           (None, 1, 16, 190)   0           activation_16[1][0]              \n",
            "                                                                 activation_17[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "quant_depthwise_conv2d_8 (Quant (None, 1, 16, 190)   1145        multiply_7[1][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "quant_conv2d_18 (QuantizeWrappe (None, 1, 16, 190)   36673       quant_depthwise_conv2d_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "quant_conv2d_19 (QuantizeWrappe (None, 1, 16, 190)   36673       quant_depthwise_conv2d_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 1, 16, 190)   760         quant_conv2d_18[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 1, 16, 190)   760         quant_conv2d_19[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 1, 16, 190)   0           batch_normalization_16[1][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 1, 16, 190)   0           batch_normalization_17[1][0]     \n",
            "__________________________________________________________________________________________________\n",
            "multiply_8 (Multiply)           (None, 1, 16, 190)   0           activation_18[1][0]              \n",
            "                                                                 activation_19[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "quant_add_4 (QuantizeWrapper)   (None, 1, 16, 190)   3           multiply_8[1][0]                 \n",
            "                                                                 multiply_8[1][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "quant_depthwise_conv2d_9 (Quant (None, 1, 16, 190)   1145        quant_add_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "quant_conv2d_20 (QuantizeWrappe (None, 1, 16, 190)   36673       quant_depthwise_conv2d_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "quant_conv2d_21 (QuantizeWrappe (None, 1, 16, 190)   36673       quant_depthwise_conv2d_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 1, 16, 190)   760         quant_conv2d_20[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 1, 16, 190)   760         quant_conv2d_21[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 1, 16, 190)   0           batch_normalization_18[1][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 1, 16, 190)   0           batch_normalization_19[1][0]     \n",
            "__________________________________________________________________________________________________\n",
            "multiply_9 (Multiply)           (None, 1, 16, 190)   0           activation_20[1][0]              \n",
            "                                                                 activation_21[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "quant_depthwise_conv2d_10 (Quan (None, 1, 16, 190)   1145        multiply_9[1][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "quant_conv2d_22 (QuantizeWrappe (None, 1, 16, 190)   36673       quant_depthwise_conv2d_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "quant_conv2d_23 (QuantizeWrappe (None, 1, 16, 190)   36673       quant_depthwise_conv2d_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 1, 16, 190)   760         quant_conv2d_22[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 1, 16, 190)   760         quant_conv2d_23[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 1, 16, 190)   0           batch_normalization_20[1][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 1, 16, 190)   0           batch_normalization_21[1][0]     \n",
            "__________________________________________________________________________________________________\n",
            "multiply_10 (Multiply)          (None, 1, 16, 190)   0           activation_22[1][0]              \n",
            "                                                                 activation_23[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "quant_add_5 (QuantizeWrapper)   (None, 1, 16, 190)   3           multiply_10[1][0]                \n",
            "                                                                 multiply_10[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "quant_depthwise_conv2d_11 (Quan (None, 1, 16, 190)   1145        quant_add_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "quant_conv2d_24 (QuantizeWrappe (None, 1, 16, 190)   36673       quant_depthwise_conv2d_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "quant_conv2d_25 (QuantizeWrappe (None, 1, 16, 190)   36673       quant_depthwise_conv2d_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 1, 16, 190)   760         quant_conv2d_24[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 1, 16, 190)   760         quant_conv2d_25[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 1, 16, 190)   0           batch_normalization_22[1][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 1, 16, 190)   0           batch_normalization_23[1][0]     \n",
            "__________________________________________________________________________________________________\n",
            "multiply_11 (Multiply)          (None, 1, 16, 190)   0           activation_24[1][0]              \n",
            "                                                                 activation_25[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "quant_flatten (QuantizeWrapper) (None, 3040)         1           multiply_11[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "quant_dense (QuantizeWrapper)   (None, 10)           30415       quant_flatten[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 998,325\n",
            "Trainable params: 979,662\n",
            "Non-trainable params: 18,663\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1mnIBvKrYcV",
        "outputId": "cd56ab6f-3b5b-4605-eb3d-d0eebf45b04e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(lr=0.0001)\n",
        "quant_aware_model.compile(optimizer=optimizer,loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
        "quant_aware_model.fit(train_images,train_labels,epochs=1,validation_split=0.1,)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1688/1688 [==============================] - 332s 194ms/step - loss: 0.0467 - accuracy: 0.9862 - val_loss: 0.0280 - val_accuracy: 0.9913\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff2c1d6ad30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpH2WAOVZYlW"
      },
      "source": [
        "**Convert to TFLite**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZGaXVgjVKZv",
        "outputId": "fd00cde8-0f58-4acd-8590-f81fe61348be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(quant_aware_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "quantized_tflite_model = converter.convert()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:2338: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:1395: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`layer.updates` will be removed in a future version. '\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, max_pooling2d_layer_call_fn, max_pooling2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn while saving (showing 5 of 240). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, max_pooling2d_layer_call_fn, max_pooling2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn while saving (showing 5 of 240). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpb91vrs43/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpb91vrs43/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xg0lZTLrD-v",
        "outputId": "e5c198cf-ed06-4e17-8e2a-865e9e010dc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(quant_aware_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "quantized_tflite_model = converter.convert()\n",
        "with open('MNIST_QAT.tflite', 'wb') as f:\n",
        "  f.write(quantized_tflite_model)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:2338: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:1395: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`layer.updates` will be removed in a future version. '\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, max_pooling2d_layer_call_fn, max_pooling2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn while saving (showing 5 of 240). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, max_pooling2d_layer_call_fn, max_pooling2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn while saving (showing 5 of 240). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmplfrdcyb6/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmplfrdcyb6/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QStrg19msERG",
        "outputId": "a25db2fd-e039-45df-e5a5-1049ab40e133",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import os\n",
        "model.save('MNIST_base_model.h5')\n",
        "print(os.stat('MNIST_base_model.h5').st_size)\n",
        "print(os.stat('MNIST_QAT.tflite').st_size)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12424840\n",
            "1333680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIm0mnWcsKAv",
        "outputId": "01e08854-6a69-4e74-d9ee-1314b7daf9d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "print(\"Float model in Mb:\", os.path.getsize('MNIST_base_model.h5') / float(2**20))\n",
        "print(\"Quantized model in Mb:\", os.path.getsize('MNIST_QAT.tflite') / float(2**20))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Float model in Mb: 11.849250793457031\n",
            "Quantized model in Mb: 1.2718963623046875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QziL5PHSM6N",
        "outputId": "81fe24e5-89a9-47fc-fa2c-3e6a1b835982",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "_, baseline_model_accuracy = model.evaluate(\n",
        "    test_images, test_labels, verbose=0)\n",
        "\n",
        "_, q_aware_model_accuracy = quant_aware_model.evaluate(\n",
        "   test_images, test_labels, verbose=0)\n",
        "\n",
        "print('Baseline test accuracy:', baseline_model_accuracy)\n",
        "print('Quant test accuracy:', q_aware_model_accuracy)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline test accuracy: 0.978600025177002\n",
            "Quant test accuracy: 0.9921000003814697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S151gmmSZsCp"
      },
      "source": [
        "**Test Accuracy on TFLite model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwm3j4snsQXi"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def evaluate_model(interpreter):\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  # Run predictions on every image in the \"test\" dataset.\n",
        "  prediction_digits = []\n",
        "  for i, test_image in enumerate(test_images):\n",
        "    test_image=tf.reshape(test_image,(28,28,1))\n",
        "    if i % 1000 == 0:\n",
        "      print('Evaluated on {n} results so far.'.format(n=i))\n",
        "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format.\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_index, test_image)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Post-processing: remove batch dimension and find the digit with highest\n",
        "    # probability.\n",
        "    output = interpreter.tensor(output_index)\n",
        "    digit = np.argmax(output()[0])\n",
        "    prediction_digits.append(digit)\n",
        "\n",
        "  print('\\n')\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "  prediction_digits = np.array(prediction_digits)\n",
        "  accuracy = (prediction_digits == test_labels).mean()\n",
        "  return accuracy"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjyzVE2KITMu",
        "outputId": "f46a7516-5127-4447-ebd8-d6d237cb748a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "test_accuracy = evaluate_model(interpreter)\n",
        "\n",
        "print('Quant TFLite test_accuracy:', test_accuracy)\n",
        "print('Quant TF test accuracy:', q_aware_model_accuracy)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluated on 0 results so far.\n",
            "Evaluated on 1000 results so far.\n",
            "Evaluated on 2000 results so far.\n",
            "Evaluated on 3000 results so far.\n",
            "Evaluated on 4000 results so far.\n",
            "Evaluated on 5000 results so far.\n",
            "Evaluated on 6000 results so far.\n",
            "Evaluated on 7000 results so far.\n",
            "Evaluated on 8000 results so far.\n",
            "Evaluated on 9000 results so far.\n",
            "\n",
            "\n",
            "Quant TFLite test_accuracy: 0.9921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-d42f3c14b6a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Quant TFLite test_accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Quant TF test accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_aware_model_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'q_aware_model_accuracy' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqSwvOv3NXkD",
        "outputId": "1d1fa87f-ee33-4000-b32a-a5ab6b3f933c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Quant TFLite test_accuracy:', test_accuracy)\n",
        "print('Quant TF test accuracy:', q_aware_model_accuracy)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Quant TFLite test_accuracy: 0.9921\n",
            "Quant TF test accuracy: 0.9921000003814697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9kBgFkRSdfC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}